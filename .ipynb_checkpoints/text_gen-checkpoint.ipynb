{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rishi Varun\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data to lower case for pre processing\n",
    "data = \"wonderland.txt\"\n",
    "raw_data = open(data).read()\n",
    "raw_data = raw_data.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '#', '$', '%', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '@', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "#index each character to integer \n",
    "chars = sorted(list(set(raw_data)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of characters are 163779\n",
      "total distinct stuff are 58\n"
     ]
    }
   ],
   "source": [
    "#lenghts of thee data\n",
    "n_chars = len(raw_data)\n",
    "n_vocabulary = len(chars)\n",
    "print(\"total number of characters are \" +str(n_chars))\n",
    "print(\"total distinct stuff are \" +str(n_vocabulary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  163679\n"
     ]
    }
   ],
   "source": [
    "#coomsidering 100 chars in each training pattern as the x and y as the char next to it and sliding it accross each character\n",
    "#of the dataset so that each char gets to learn \n",
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "\tseq_in = raw_data[i:i + seq_length]\n",
    "\tseq_out = raw_data[i + seq_length]\n",
    "\tdataX.append([char_to_int[char] for char in seq_in])\n",
    "\tdataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to finalise our training data we need to one hot encode the output that is Y\n",
    "#restructuring x_data to (sample, timesteps, features)\n",
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "X = X / float(n_vocabulary)\n",
    "Y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our training data is now pre processed and ready to be fit into the LSTM model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(Y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "163679/163679 [==============================] - 640s 4ms/step - loss: 2.9800\n",
      "Epoch 2/5\n",
      "163679/163679 [==============================] - 649s 4ms/step - loss: 2.8022\n",
      "Epoch 3/5\n",
      "163679/163679 [==============================] - 644s 4ms/step - loss: 2.7147\n",
      "Epoch 4/5\n",
      "163679/163679 [==============================] - 634s 4ms/step - loss: 2.6430\n",
      "Epoch 5/5\n",
      "163679/163679 [==============================] - 653s 4ms/step - loss: 2.5782\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18157cf5f98>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the training data into the LSTM\n",
    "model.fit(X,Y, epochs = 5, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('saved_stuff.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have trained our model on five epochs due to limited gpu service on my system \n",
    "now we will predict further text using the seed sequence form \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" she\n",
      "had kept a piece of it in her pocket) till she was about a foot high:\n",
      "then she walked down the l \"\n",
      "are th the hare to the hare to the hare to the hare to the hare and the woete to the hare to the hare to the hare to the hare to the hare to the hare and the woete to the hare to the hare to the hare to the hare to the hare to the hare and the woete to the hare to the hare to the hare to the hare to the hare to the hare and the woete to the hare to the hare to the hare to the hare to the hare to the hare and the woete to the hare to the hare to the hare to the hare to the hare to the hare and the woete to the hare to the hare to the hare to the hare to the hare to the hare and the woete to the hare to the hare to the hare to the hare to the hare to the hare and the woete to the hare to the hare to the hare to the hare to the hare to the hare and the woete to the hare to the hare to the hare to the hare to the hare to the hare and the woete to the hare to the hare to the hare to the hare to the hare to the hare and the woete to the hare to the hare to the hare to the hare to the hare to\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "# generate characters\n",
    "for i in range(1000):\n",
    "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "\tx = x / float(n_vocabulary)\n",
    "\tprediction = model.predict(x, verbose=0)\n",
    "\tindex = numpy.argmax(prediction)\n",
    "\tresult = int_to_char[index]\n",
    "\tseq_in = [int_to_char[value] for value in pattern]\n",
    "\tsys.stdout.write(result)\n",
    "\tpattern.append(index)\n",
    "\tpattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
